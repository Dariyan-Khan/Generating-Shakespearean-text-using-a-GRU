{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\n",
    "with open(filepath) as f:\n",
    "    shakespeare_text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n !$&',-.3:;?abcdefghijklmnopqrstuvwxyz\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(sorted(set(shakespeare_text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[20, 6, 9, 8, 3]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences([\"First\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['f i r s t']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sequences_to_texts([[20, 6, 9, 8, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_id = len(tokenizer.word_index) # number of distinct characters\n",
    "dataset_size = tokenizer.document_count # total number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1\n",
    "train_size = dataset_size * 90 // 100\n",
    "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 100\n",
    "window_length = n_steps + 1 # target = input shifted 1 character ahead\n",
    "dataset = dataset.repeat().window(window_length, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = dataset.shuffle(10000).batch(batch_size)\n",
    "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 100, 39) (32, 100)\n"
     ]
    }
   ],
   "source": [
    "for X_batch, Y_batch in dataset.take(1):\n",
    "    print(X_batch.shape, Y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31370/31370 [==============================] - 11946s 381ms/step - loss: 1.4661\n",
      "Epoch 2/10\n",
      "31370/31370 [==============================] - 8210s 262ms/step - loss: 1.3634\n",
      "Epoch 3/10\n",
      "31370/31370 [==============================] - 7968s 254ms/step - loss: 1.3437\n",
      "Epoch 4/10\n",
      "31370/31370 [==============================] - 8707s 278ms/step - loss: 1.3326\n",
      "Epoch 5/10\n",
      "31370/31370 [==============================] - 9842s 314ms/step - loss: 1.3253\n",
      "Epoch 6/10\n",
      "31370/31370 [==============================] - 11645s 371ms/step - loss: 1.3200\n",
      "Epoch 7/10\n",
      "31370/31370 [==============================] - 10854s 346ms/step - loss: 1.3157\n",
      "Epoch 8/10\n",
      "31370/31370 [==============================] - 9241s 295ms/step - loss: 1.3128\n",
      "Epoch 9/10\n",
      "31370/31370 [==============================] - 8246s 263ms/step - loss: 1.3104\n",
      "Epoch 10/10\n",
      "31370/31370 [==============================] - 11798s 376ms/step - loss: 1.3084\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id],\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.GRU(128, return_sequences=True,\n",
    "                     dropout=0.2, recurrent_dropout=0.2),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(max_id,\n",
    "                                                    activation=\"softmax\"))\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "history = model.fit(dataset, steps_per_epoch=train_size // batch_size,\n",
    "                    epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    X=np.array(tokenizer.texts_to_sequences(texts))-1\n",
    "    return tf.one_hot(X,max_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_char(text, temperature=1):\n",
    "    X_new=preprocess([text])\n",
    "    y_proba=model.predict(X_new)[0,-1:,:]\n",
    "    rescaled_logits=tf.math.log(y_proba)/temperature\n",
    "    char_id=tf.random.categorical(rescaled_logits, num_samples=1)+1\n",
    "    return tokenizer.sequences_to_texts(char_id.numpy())[0]\n",
    "\n",
    "def complete_text(text,n_chars=1000,temperature=1):\n",
    "    for _ in range(n_chars):\n",
    "        text+=next_char(text,temperature)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will the budy sister.\n",
      "\n",
      "menenius:\n",
      "what! where shall'\n"
     ]
    }
   ],
   "source": [
    "print(complete_text(\"w\", temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first citizen:\n",
      "o madam, to the other baste. what's the enough?\n",
      "\n",
      "treasure:\n",
      "why, would i know 'tis thus in your counsel in the storing perhopies;\n",
      "for when my advised woo i' the remonaste,\n",
      "we hear the better lunators, which will charge her poor baws,\n",
      "that be so says shall be more swork her soblicient more.\n",
      "\n",
      "hortensio:\n",
      "and say you give me but?\n",
      "\n",
      "katharina:\n",
      "o belly, they was no ready stay to save\n",
      "the scold me the ale.\n",
      "who was her? why, malicious tranio, since with the swer to beaute.\n",
      "\n",
      "menenius:\n",
      "belly the matter, he they are the sweal us curse\n",
      "and fair the store--\n",
      "for this men are be so,\n",
      "sirrah you this godss with it; and that the coat.\n",
      "\n",
      "first citizen:\n",
      "all, knock leave thee, sir; and them esteeds,\n",
      "as one of friend, in perite is girl! this idle from \n",
      "menenius:\n",
      "what, this accised upon you. where this gremio.\n",
      "to in the rail. this rogue stribe.\n",
      "it i\n"
     ]
    }
   ],
   "source": [
    "#### print(complete_text(\"a\", temperature=1))\n",
    "\n",
    "# all as i will part\n",
    "# 'tis slrums from my best begun: with them am\n",
    "# to the anselves, what the elder of double comes are their\n",
    "# touches deliver to a chore.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('''first citizen:\n",
    "o madam, to the other baste. what's the enough?\n",
    "\n",
    "treasure:\n",
    "why, would i know 'tis thus in your counsel in the storing perhopies;\n",
    "for when my advised woo i' the remonaste,\n",
    "we hear the better lunators, which will charge her poor baws,\n",
    "that be so says shall be more swork her soblicient more.\n",
    "\n",
    "hortensio:\n",
    "and say you give me but?\n",
    "\n",
    "katharina:\n",
    "o belly, they was no ready stay to save\n",
    "the scold me the ale.\n",
    "who was her? why, malicious tranio, since with the swer to beaute.\n",
    "\n",
    "menenius:\n",
    "belly the matter, he they are the sweal us curse\n",
    "and fair the store--\n",
    "for this men are be so,\n",
    "sirrah you this godss with it; and that the coat.\n",
    "\n",
    "first citizen:\n",
    "all, knock leave thee, sir; and them esteeds,\n",
    "as one of friend, in perite is girl! this idle from \n",
    "menenius:\n",
    "what, this accised upon you. where this gremio.\n",
    "to in the rail. this rogue stribe.\n",
    "it i''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong, the city.\n",
      "\n",
      "hortensio:\n",
      "give himself, receive the rightal blow the rest,\n",
      "they burn users, that must tell this give be honour\n",
      "and me all particially as for it;\n",
      "which gives a suitor heard withal instrued\n",
      "and make god pirped in althe takes oc very deeds.\n",
      "\n",
      "painio:\n",
      "alive to common; even are away, i may leave her\n",
      "balls pass, since i proceed and live it find for\n",
      "the stolence hath thus flound the state,\n",
      "but knock you faol, was more a counsel for the good the belly\n",
      "would be loud and so.\n",
      "behive you what you will not hake? you danciy perhaps of me;\n",
      "he'll part the worsporants ere it?\n",
      "\n",
      "maniantio:\n",
      "become it that shall socient the good master,\n",
      "this good fyceinor, well\n",
      "his faults, i have her colding me not in my tears,\n",
      "and do i will content to be marcived by a fair in hell:\n",
      "if i proceed us belly once.\n",
      "\n",
      "bianca:\n",
      "who shall be countent to her way to leave not\n",
      "his own prince well; even be not rates, i did no foll\n",
      "if you plead boar beneyous the ready us words:\n",
      "why ched you state, the opentastal pains at\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "letters='qwertyuiopasdfghjklzxcvbnm'\n",
    "index=randint(0,25)\n",
    "\n",
    "print(complete_text(letters[index], temperature=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/dariyankhan/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/dariyankhan/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
